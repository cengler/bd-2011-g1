\section{Conclusiones}

\subsection{\fs}
Vemos que ninguna de las estrategias de reemplazo de páginas es mejor a otra.
\newline
Pero uno puede observar resultados interesantes cuando se necesita recorrer más de una vez la traza, dado que ahora hay oportunidad de cachear p áginas pedidas anteriormente.
\newline
Para el caso de dos lecturas sucesivas sobre la misma traza podemos considerar dos escenarios:
\begin{itemize}
 \item    \textbf{La cantidad de frames en buffer es menor a la cantidad de páginas pedidas}: la única estrategia que tiene Hit-Rate mayor a 0 es MRU. FIFO y LRU cuando necesitan alojar una nueva página empiezan desalojando la primera en ser almacenada y este comportamiento impide reaprovechar esas páginas en la segunda lectura de la traza.
 \item    \textbf{La cantidad de frames en buffer en mayor o igual a la cantidad de páginas pedidas}: en este escenario las tres estrategias muestran un HitRate del 50\% dado que si bien en la primera lectura no tienen ninguna página en buffer, para la segunda no tuvieron que desalojar ninguna(son todos hits).
\end{itemize}

\subsection{Index Scan Clustered}
Si suponemos que hay un índice clustered sobre un atributo $a$ de una relación $A$ y la solicitud que se hizo es para un rango $c<a<b$. En este caso, el HitRate es igual a 0 dado que accedo por el índice al bloque donde se encuentra $c$ y recorro todos los bloques hasta que encuentro $d$, por lo tanto no hay posibilidad de tener cacheado bloques previamente solicitados.\newline
Hay casos particulares donde el uso repetido de Index Scan Clustered implica un HitRate mayor a 0. Ejemplos de estos casos son:
\begin{itemize}
	\item Dos lecturas sucesivas sobre el mismo rango. El HitRate de esta operación daría resultados análogos a los obtenidos con \fs cuando hicimos dos lecturas seguidas sobre el mismo archivo.
	\item Casos donde se realizan lecturas de rangos con intersección distinta a vacío, lo cual puede permitir la reutilización de bloques pertenecientes a la intersección de estos rangos si los mismos se encuentran en el Buffer.
\end{itemize}

\subsection{Index Scan Unclustered}
  TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO TODO\newline

\subsection{BNLJ}
Podemos considerar los siguientes escenarios:
\begin{itemize}
  \item \textbf{Las páginas de R pueden ser cacheadas en memoria en su totalidad} dejando por lo menos dos frames de memoria libres, uno para S y otro para el resultado del JOIN. Este caso no es muy interesante, ya que con cualquier algoritmo de reemplazo el Hit-Rate es cero. La explicación es la siguiente: tenemos cacheado R completamente y lo que necesitamos ir iterando es el bloque de S contra el cuál cruzamos los bloques de R. \newline
  Es decir:
  \begin{itemize}
    \item En la primera iteración cruzamos todos los bloques de R contra el primero de S y obtenemos un Miss(ninguno estaba cargado previamente)
    \item Cargamos en memoria el segundo bloque de S
    \item De ser necesario reemplazar una página, hay que tener en cuenta que el único frame que hizo release fue el anterior de S y volvemos a obtener otro Miss correspondiente al nuevo bloque de S recién cargado
    \item Terminamos de iterar sobre S sin haber reutilizado ningún frame(todos Misses).
  \end{itemize}
  \item \textbf{La totalidad de las páginas de R no pueden ser cacheadas en memoria} y se cuenta con un buffer de tamaño fijo.\\
Para este escenario se corrieron pruebas donde se var\'ia la cantidad de bloques dedicados a R \footnote{Ver subsecci\'on BNLJ en sección Evaluación de Estrategias} 
    \begin{itemize}
     \item De las pruebas se pueda observar lo siguiente: 
	\begin{itemize}
	 \item Sean $B_{MR}$ los bloques disponibles para cahear R,
	 \item \# $hits = B_{S} \times (B_{R}-1)$ y
         \item \# $miss = B_{S} + B_{R}$
	 \item Luego $HitRate = \frac{B_{S} \times (B_{R}-1)}{B_{S} \times (B_{R}-1)+B_{S}+B_{R}}$
	\end{itemize}
    \end{itemize}

\end{itemize}

